

<!doctype html>
<html lang="en" class="no-js" style="height: 100%;position: relative;">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Research - Jie Yang @ TU Delft</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Jie Yang @ TU Delft">
<meta property="og:title" content="Research">


  <link rel="canonical" href="http://localhost:4000/project.html">
  <meta property="og:url" content="http://localhost:4000/project.html">







  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Jie Yang",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Jie Yang @ TU Delft Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->
<link rel="shortcut icon" href="/images/favicon.ico">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<!-- end custom head snippets -->

  </head>

  <body style="height: 100%;position: relative;">
	<div id="body_container" style="min-height: 100vh; display: block; position: relative; padding-bottom: 100px;">
    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    
<style>
@media all and (max-width: 480px) {
    #menu_title { display: none; }
}
</style>
<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg" id="menu_title"><a href="http://localhost:4000/">Jie Yang @ TU Delft</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/project.html">Research</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/paper.html">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/people.html">Team</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/education.html">Education</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/activities.html">Activities</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <a href="http://localhost:4000" style="text-decoration: none;"><div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.jpg" class="author__avatar" alt="Jie Yang">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Jie Yang</h3>
    <p class="author__bio">Assistant Professor</p>
  </div></a>

  <div class="author__urls-wrapper">
    <!--<button class="btn btn--inverse">Follow</button>-->
    <ul class="author__urls social-icons">
      
      
      
      
        <li><i class="fa fa-fw fa-envelope-square" aria-hidden="true"></i> j.yang-3@<span style="display: none;">ignoreme-</span>tudelft.nl</li>
      
      
      
        <li><a href="https://twitter.com/yangjiera"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
        <li><a href="https://www.linkedin.com/in/jiy"><i class="fa fa-fw fa-linkedin-square" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
	  
        <li><a href="https://scholar.google.com/citations?user=DAlsOOEAAAAJ"><i class="ai ai-google-scholar-square ai-fw"></i> Google Scholar</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Research">
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          <!--<h1 class="page__title" itemprop="headline">Research
</h1>-->
          
        
        
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        

<h1>Research</h1>

<h3><i>"Building AI with people</i></h3>

To build reliable and trustworthy AI, fundamental questions need to be answered including: what data do we need? how do machine learning models work and when do they fail? and how to evaluate the model from the stakeholders' and systemic perspective? To answer those questions, my research takes a human-in-the-loop approach that leverages human understanding of the task and the world, and that caters to the needs and desires of stakeholders. As contributions, my research creates a new human-in-the-loop methodology for machine learning, with a set of methods and tools for 
<li>Human-Enhanced Data Management: data <a href="/research.html/#OpenCrowd">creation</a>, <a href="/research.html/#Scalpel-CD">cleaning</a>, and <a href="/research.html/#Perspective">debiasing</a>;</li>
<li>Human-Centered Machine Learning: model <a href="/research.html/#SECA">explanation</a> and <a href="/research.html/#ARCH">debugging</a>;</li>
<li>Human-AI Collaboration: systemic <a href="/research.html/#ValuableML">evaluation</a> and <a href="/research.html/#ContiLearn">improvement</a>.</li>
<br>

My research methodology is both empirical and theoretical, with primary activities characterized by the design, implementation, and analysis of human studies, computational algorithms, and human-in-the-loop systems. I particularly value the collaboration with scientists from other disciplines and experts from various application domains, together with whom me and my <a href="people">research team</a> develop usable tools to make real-world impacts. 

<!--I am passionate about making AI more "knowledgeable" and consider human intelligence as an indispensable means to understanding the knowns and unknowns of intelligent machines, through human interpretation of machine behavior and human creation of domain knowledge. I also consider computational algorithms as a vital tool to assist humans in knowledge reasoning at scale, under uncertainty. My research methodology is therefore both empirical and theoretical, with primary activities characterized by the design, implementation, and analysis of human studies, computational algorithms, and human-in-the-loop systems.-->


<br/>
<br/>
<h1>Projects</h1>

<h3><a id="ARCH">[Model Debugging] ARCH: Know What Your Machine Doesn't Know</a></h3>
Despite their impressive performance, machine learning systems remain largely unreliable in safety-, trust- and ethically sensitive domains. Recent discussions in several subfields of AI have reached a consensus of knowledge need in machines, but few discussions have touched upon the diagnosis of what knowledge is needed. This project aims to develop human-in-the-loop methods and tools for the diagnosis of machine unknowns. We consider humans to be essential in understanding the knowns and unknowns of intelligent machines, through human interpretation of machine behaviour and creation of knowledge requirements. We also see computational algorithms as vital tools that can assist humans in knowledge reasoning at scale, under uncertainty. <br>
Knowing machine unknowns is essential in any context both for making AI (debugging the machine) and for using AI (deciding when to trust the machine output). We envision that this project will have a tremendous scientific and practical impact, across all areas where AI and machine learning are applied.
<!--h3>Publications</h3-->
<br/>
<br/>


<h3><a id="SECA">[Model Explanation] SECA: Know How Your Machine Works</a></h3>
State-of-the-art machine learning models employ neural models that generally operate as “black-boxes”. The opaqueness of these models has become a major obstacle for deploying, debugging, and tuning them. To understand how those models work, it is essential to explain model behaivor in human-understandable language. This project aims to introduces a scalable human-in-the-loop approach for global interpretability of machine learning models. We employ local interpretability methods to highlight salient input units and leverage human inteligence to annotate such units with semantic concepts. Those semantic concepts are then aggregated into a tabular representation of images to facilitate automatic statistical analysis of model behavior. Our approach supports multi-concept interpetability need for both model validation and exploration.
<!--h3>Publications</h3-->
<br/>
<br/>

<li><a href="pdf/balayn2021www.pdf">What do You Mean? Interpreting Image Classification with Crowdsourced Concept Extraction and Analysis (WWW2021)</a></li>

<li><a href="pdf/arous2021aaai.pdf">MARTA: Leveraging Human Rationales for Explainable Text Classification (AAAI2021)</a></li>


<h3><a id="OpenCrowd">[Data Creation] OpenCrowd: Large-scale People Engagement for Data Creation</a></h3>
Large-scale training data is the cornerstone of machine learning. Creating such data is a long, laborious, and usually expensive process, especially when it requires domain knowledge. Crowdsourcing provides a cost-effective way to find  in a short time a large number of contributors, who as a whole possesses a broad knowledge in specific domains. This project aims to develop OpenCrowd, a large-scale expert finding and engagement platform for training data creation. The platform  models relevant participant properties such as expertise, location, and cultural background, and employs peer routing techniques to scale out the finding for experts. It employs peer grading techniques for effective and efficient outcome aggregation and assessment. OpenCrowd further allows for steering the data creation process towards the preference over certain data properties using only a small amount of seed data.
<!--h3>Publications</h3-->
<br/>
<br/>

<li><a href="pdf/arous2020www.pdf">OpenCrowd: A Human-AI Collaborative Approach for Finding Social Influencers via Open-Ended Answers Aggregation (WWW2020)</a></li>

<li><a href="pdf/mesbah2019emnlp.pdf">Training Data Augmentation for Detecting Adverse Drug Reactions in User-Generated Content (EMNLP2019)</a></li>

<li><a href="pdf/arous2021www.pdf">Peer Grading the Peer Reviews: A Dual-Role Approach for Lightening Scholarly Paper Review Processes (WWW2021)</a></li>


<h3><a id="Scalpel-CD">[Data Denoise] Scalpel-CD: Reducing Label Noise in Training Data</a></h3>
The success of machine learning techniques heavily relies on not only the quantity but also the quality of labeled training data. Incorrect labels in the training data are generally difficult to identify and have become a main obstacle for developing, deploying, and improving machine learning models. This project introduces Scalpel-CD, a first-of-its-kind system that leverages both human and machine intelligence to debug noisy labels from the training data of machine learning systems. Our system identifies potentially wrong labels by exploiting data distributions in the underlying latent feature space, and employs a data sampler which selects data instances that would benefit the most from being inspected by the crowd. The manually verified labels are then propagated to similar data instances in the original training data by exploiting the underlying data structure, thus scaling out the contribution from the crowd. <br>
Scalpel-CD is designed with a set of algorithmic solutions to automatically search for the optimal configurations for different types of training data, in terms of the underlying data structure, noise ratio, and noise types (random vs. structural). 
<!--h3>Publications</h3-->
<br/>
<br/>

<li><a href="pdf/yang2019www_scalpel.pdf">Scalpel-CD: Leveraging Crowdsourcing and Deep Probabilistic Modeling for Debugging Noisy Training Data (WWW2019)</a></li>


<h3><a id="Perspective">[Data Debiasing] Perspective: Identifying and Characterizing Data Atypicality</a></h3>
High-quality data plays an important role in developing reliable machine learning models. Incompleteness of training data or inherent biases can lead to negative and sometimes damaging effects, particularly in critical domains such as transport, finance, or medicine. It also implies that high-quality test data is vital for reliable and trustworthy evaluation. Despite that, what makes an item hard to classify remains an unstudied topic. This project aims to provide a first-of-its-kind, model-agnostic characterization of data atypicality based on human understanding. We consider the setting of data classification “in the wild”, where a large number of unlabeled items are accessible, and introduce a scalable and effective human computation approach for proactive identification and characterization of atypical data items. <br>
Our approach enables the creation of a feedback loop in the lifecycle of an machine learning model, thereby enabling a never-ending learning scenario where model performance can continuously improve. It is effective, cost-efficient, and generic to any machine learning tasks.
<!--h3>Publications</h3-->
<br/>
<br/>


<h3><a id="ValuableML">[Systemic Evaluation] ValuableML: Co-Design of Value Metrics for ML</a></h3>
For decades, the primary way to develop and assess machine learning (ML) models has been based on accuracy metrics (e.g. precision, recall, F1, AUC). We have largely forgotten that ML models are applied in an organisation or societal context because they provide value to people. This leads to a significant disconnection between the amazing progress of ML research – with corresponding sky-high expectations of professionals in any field – and the limited adoption of ML. We see the need for new value-based metrics for the development and evaluation of ML models. These will cater to the actual needs and desires of users and relevant stakeholders, and will be tailored to the cost structure in specific use cases. <br>
This project aims to introduce proper value metrics and processes. We will create them by answering two fundamental questions: what makes a model 'good'? and what is the value of a model? We use a co-design methodology emphasising the importance of involving stakeholders in the creation of metrics, so they represent the collective interest of all involved.
<!--h3>Publications</h3-->
<br/>
<br/>

<li><a href="pdf/casati2021neurips.pdf">On the Value of ML Models (WHMD@Neurips2021)</a></li>

<li><a href="pdf/sayin2021hcomp.pdf">The Science of Rejection: A Research Area for Human Computation (HCOMP2021)</a></li>


<h3><a id="ContiLearn">[Systemic Improvement] ContiLearn: Continual Learning from People</a></h3>
To create a sustainable human-AI ecosystem where AI can continuously serve the purpose and acts to the benefit of people, it is of key importance to have an approach that can allow machine learning models to actively and continuously learn from users and stakeholders over time. This project aims to introduce such an approach, referred to as ContiLearn, that allows to create a never-ending learning scenario where machine learning models actively and continuously learn from relevant stakeholders, while maximizing the diversity of viewpoints and the coverage and the representativeness of real-world situations.
<!--h3>Publications</h3-->
<br/>
<br/>

<li><a href="pdf/bhardwaj2020aaai.pdf">A Human-AI Loop Approach for Joint Keyword Discovery and Expectation Estimation in Micropost Event Detection (AAAI2020)</a></li>

<li><a href="pdf/ostapuk2019www.pdf">ActiveLink: Deep Active Learning for Link Prediction in Knowledge Graphs (WWW2019)</a></li>

<li><a href="pdf/yang2018www.pdf">Leveraging Crowdsourcing Data For Deep Active Learning - An Application: Learning Intents in Alexa (WWW2018)</a></li>


        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

      


    </div>

    
  </article>

  
  
</div>


    </script>

    <div class="page__footer" style="position: absolute; bottom: 0; width: 100%;">
      <footer>
        
        

<div class="page__footer-follow">
  <ul class="social-icons">
    
    
    
    
    
	<!--
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>-->
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Jie Yang. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>. 
  <!-- See the background image <a href="http://localhost:4000/background.html">here</a>. -->
</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-67280559-1', 'auto');
  ga('send', 'pageview');
</script>





    </div>
  </body>
</html>

